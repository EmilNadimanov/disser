{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "SnLY0VTXRgEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc8fc5e-146c-445c-e121-d551ded87e32"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install razdel\n",
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHZiNLgTRf8C",
        "outputId": "06f938fc-d627-444d-ef23-3b184d7936db"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149860 sha256=b7116a3b2988faa0876ab5423cdfc154652f27598d63a288f8df0de36800188f\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import re\n",
        "from razdel import tokenize\n",
        "\n",
        "from torchvision.models import googlenet\n",
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Compose, Normalize, Resize, ToTensor, RandomErasing, RandomAffine\n",
        "from PIL import Image\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "from tqdm.notebook import tqdm\n",
        "from string import punctuation, whitespace"
      ],
      "metadata": {
        "id": "UnUVs9BgRjQW"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Инференс"
      ],
      "metadata": {
        "id": "3xrYCqgHoIeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Инференс модели torch. Инфраструктура"
      ],
      "metadata": {
        "id": "jSmYxssToVIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Полезности (запусти меня)"
      ],
      "metadata": {
        "id": "yiTpmAoS_Gb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные для инференса"
      ],
      "metadata": {
        "id": "vcr9UWmTDEUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import img_as_bool\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.morphology import skeletonize, binary_closing, thin\n",
        "import skimage"
      ],
      "metadata": {
        "id": "4HWE0byOea48"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/drive/MyDrive/Disser/dictation_text.txt .\n",
        "# !cp /content/drive/MyDrive/Disser/dataset_more_data.zip .\n",
        "# !cp /content/drive/MyDrive/Disser/words.zip .\n",
        "# !unzip -qq -o dataset_more_data.zip\n",
        "# !unzip -qq -o words.zip\n",
        "!ls dataset_more_data\n",
        "!ls dataset_more_data | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcQuU8O4JeTE",
        "outputId": "6b109a74-3e13-4384-cd71-2dda6b64684e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dash\tq_mark\tб  г  е  ж  и  к  м  о\tр  т  ф  ц  ш  ъ  ь  ю\n",
            "e_mark\tа\tв  д  ё  з  й  л  н  п\tс  у  х  ч  щ  ы  э  я\n",
            "36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Disser/dataset_cropped_chars.zip .\n",
        "!unzip -qq -o dataset_cropped_chars.zip\n",
        "!ls dataset_cropped_chars\n",
        "!ls dataset_cropped_chars | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thpf01xFnyvx",
        "outputId": "d9651d8a-a858-491d-b5b1-def23a1d7894"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dash\tа  Б  г  е  Ж  И  К  м\tН  п  Р  т  У  Х  ш  ы\tю\n",
            "e_mark\tА  в  д  ё  з  й  л  М\tо  П  с  Т  ф  ц  щ  ь\tя\n",
            "q_mark\tб  В  Д  ж  и  к  Л  н\tО  р  С  у  х  ч  ъ  э\tЯ\n",
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "9njDYPhqJXGq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "препроцессинг"
      ],
      "metadata": {
        "id": "7Mte3oslCro9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_margin(pil_img, top=0, right=0, bottom=0, left=0, color=(255,255,255)):\n",
        "    \"\"\"\n",
        "    add margin to an image. Any side you want!\n",
        "    \"\"\"\n",
        "    width, height = pil_img.size\n",
        "    new_width = width + right + left\n",
        "    new_height = height + top + bottom\n",
        "    result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
        "    result.paste(pil_img, (left, top))\n",
        "    return result\n",
        "\n",
        "def binarize(pic):\n",
        "    \"\"\"\n",
        "    get a representation of this picture as an numpy matrix\n",
        "    numbers are floating-point non-integers (8-bit pixels, black and white)\n",
        "    \"\"\"\n",
        "    wd, ht = pic.size\n",
        "    pixels = np.array(pic.convert('L').getdata(), np.uint8)\n",
        "    bin_img = 1 - (pixels.reshape((ht, wd)) / 255.0)\n",
        "    return bin_img\n",
        "\n",
        "def put_in_a_box(char: 'Image'):\n",
        "    \"\"\"\n",
        "    cut an image with white background, making it a \"box\" that borders the first encountered non-white\n",
        "    parts of the image, e.g. bordering each side of a letter\n",
        "    \"\"\"\n",
        "    bin_img = binarize(char)\n",
        "    height, width = bin_img.shape\n",
        "    def find_border(bin_img):\n",
        "        for (idx, row) in enumerate(bin_img):\n",
        "            if np.sum(row) > 0:\n",
        "                return idx\n",
        "    \n",
        "    left = find_border(bin_img.T)\n",
        "    top = find_border(bin_img)\n",
        "    if left is None or top is None:\n",
        "      return None\n",
        "    right = width - find_border(bin_img.T[::-1, :])\n",
        "    bottom = height - find_border(bin_img[::-1, :])\n",
        "    \n",
        "    return char.crop((left, top, right, bottom))\n",
        "\n",
        "def pil2cv(pil_img):\n",
        "  return np.array(pil_img)[:, :, ::-1]\n",
        "\n",
        "def cv2pil(cv2_img):\n",
        "  return Image.fromarray(cv2_img)\n",
        "\n",
        "def delete_bad_contour(image: Image, min_area=30):\n",
        "  # Load image, convert to grayscale, Gaussian blur, Otsu's threshold\n",
        "  image = pil2cv(image)\n",
        "  blur = cv2.GaussianBlur(image, (3,3), 2)\n",
        "  gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n",
        "  thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  # Filter using contour area and remove small noise\n",
        "  cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
        "  for c in cnts:\n",
        "      area = cv2.contourArea(c)\n",
        "      if area < min_area:\n",
        "          cv2.drawContours(thresh, [c], -1, (0,0,0), -1)\n",
        "  color_converted = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
        "  res = cv2.bitwise_and(image-255, color_converted)\n",
        "  color_converted = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
        "  pil_image=cv2pil(color_converted+255)\n",
        "  return pil_image\n",
        "\n",
        "def preprocess(image: Image, \n",
        "               min_contour, \n",
        "               padding=5,\n",
        "               deacrease_contour_if_none=False):\n",
        "  while True:\n",
        "    only_large_countour = delete_bad_contour(image, min_contour)\n",
        "    boxed = put_in_a_box(only_large_countour)\n",
        "    if boxed is None and deacrease_contour_if_none:\n",
        "      min_contour -= 1\n",
        "    else: break\n",
        "  return add_margin(boxed, padding,padding,padding,padding)"
      ],
      "metadata": {
        "id": "UrzLDosQCqgD"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "для сохранения файлов в одном месте без конфликта наименований"
      ],
      "metadata": {
        "id": "QdIsdfqyCt3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "vj0b_IWPaf-7"
      },
      "outputs": [],
      "source": [
        "def next_path(path_pattern):\n",
        "    \"\"\"\n",
        "    Finds the next free path in an sequentially named list of files\n",
        "    e.g. path_pattern = 'file-%s.txt':\n",
        "    \"\"\"\n",
        "    i = 1\n",
        "\n",
        "    while os.path.exists(path_pattern % i):\n",
        "        i = i * 2\n",
        "\n",
        "    a, b = (i // 2, i)\n",
        "    while a + 1 < b:\n",
        "        c = (a + b) // 2 # interval midpoint\n",
        "        a, b = (c, b) if os.path.exists(path_pattern % c) else (a, c)\n",
        "\n",
        "    return path_pattern % b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для загрузки модели"
      ],
      "metadata": {
        "id": "hAb-g6iJDMNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_custom_model_from_pt(fp, model, device, eval=True):\n",
        "    model.load_state_dict(torch.load(fp, map_location=torch.device(device)))\n",
        "    if eval:\n",
        "        model.eval()\n",
        "    return model\n",
        "\n",
        "def load_resnet18_model_from_pt(fp, num_of_classes, device, eval=True):\n",
        "    model = resnet18(pretrained=True)\n",
        "    model.fc = torch.nn.Linear(512, num_of_classes)\n",
        "    model.load_state_dict(torch.load(fp, map_location=torch.device(device)))\n",
        "    if eval:\n",
        "        model.eval()\n",
        "    return model\n",
        "\n",
        "def load_googlenet_model_from_pt(fp, num_of_classes, device, eval=True):\n",
        "    model = googlenet(pretrained=True)\n",
        "    model.fc = torch.nn.Linear(1024, num_of_classes)\n",
        "    model.load_state_dict(torch.load(fp, map_location=torch.device(device)))\n",
        "    if eval:\n",
        "        model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "0LJua8ODjC30"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для предсказания по модели torch"
      ],
      "metadata": {
        "id": "3QENITMWDPRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(model_instance, class_names, image, transform, device=\"cpu\"):\n",
        "    image_tensor = transform(image).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input = torch.autograd.Variable(image_tensor)\n",
        "    input = input.to(device)\n",
        "    output = model_instance(input)\n",
        "    index = output.data.cpu().numpy().argmax()\n",
        "    return class_names[index]"
      ],
      "metadata": {
        "id": "jgm1_L-tDPAh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Цепь маркова"
      ],
      "metadata": {
        "id": "A-Bj6bR1WyqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MarkovChain:\n",
        "    START_TOKEN = \" \"\n",
        "    \n",
        "    def __init__(self, text: str, sequence_size:int):\n",
        "        \"\"\"\n",
        "        Markov chain allows us to predict the next element of a sequence based\n",
        "         on the current state. Here we predict the next character based of a\n",
        "         given sequence of characters.\n",
        "        \n",
        "        parameters:\n",
        "            text:          one string that contains the whole text on which the chain\n",
        "                            is going to be based\n",
        "            sequence_size: to predict the next element we take into account the last N\n",
        "                            elements of a given sequence. This parameter is the N.\n",
        "        \"\"\"\n",
        "        self.seq_size = sequence_size\n",
        "        self.text = text\n",
        "        self.corpus = self.normalize()\n",
        "        self.all_chars = sorted(list(set(''.join(self.corpus)) - set(whitespace)))\n",
        "        self.char_to_id = self.__char_to_id__()\n",
        "        self.id_to_char = {v: k for k, v in self.char_to_id.items()}\n",
        "        self.M = self.__coocurrance_matrix__()\n",
        "        \n",
        "    def predict_next_char(self, chars) -> str:\n",
        "        assert len(chars) == self.seq_size\n",
        "        \n",
        "        id_tupl = tuple([self.char_to_id[char] for char in chars])\n",
        "        next_id: int = np.argmax(self.M[id_tupl])\n",
        "        if next_id == 0:\n",
        "            # Every char has equal probability, most possibly 0, and <END> tag is returned\n",
        "            return None \n",
        "        next_char: str = self.id_to_char[next_id]\n",
        "        return next_char\n",
        "        \n",
        "    def proba(self, prev, next_) -> float:\n",
        "        \n",
        "        try:\n",
        "          assert len(prev) == self.seq_size\n",
        "          assert next_ in self.char_to_id\n",
        "          id_tupl = tuple([self.char_to_id[char] for char in prev])\n",
        "          next_id = self.char_to_id[next_]\n",
        "          proba = self.M[id_tupl][next_id]\n",
        "        except:\n",
        "          proba = 0\n",
        "        return proba\n",
        "    \n",
        "    def normalize(self):\n",
        "        tokens = [t.text.strip(punctuation) for t in tokenize(self.text)]\n",
        "        return [t for t in tokens if len(t) > 0]\n",
        "    \n",
        "    def __coocurrance_matrix__(self):\n",
        "        M = np.zeros(tuple(\n",
        "                    [len(self.char_to_id)] * (self.seq_size+1)\n",
        "                 ))\n",
        "        for word in self.corpus:\n",
        "            # srez has size `self.seq_size` + 1\n",
        "            for srez in self.__char_groups__(word):\n",
        "                ids = tuple([self.char_to_id[char] for char in srez])\n",
        "                M[ids] += 1\n",
        "        return M\n",
        "                \n",
        "        \n",
        "    def __char_to_id__(self):\n",
        "        char_to_id = {\n",
        "            MarkovChain.START_TOKEN: 0,\n",
        "        }\n",
        "        for i, char in enumerate(self.all_chars):\n",
        "            i += 1\n",
        "            char_to_id[char] = i\n",
        "        return char_to_id\n",
        "        \n",
        "    def __char_groups__(self, word):\n",
        "        word: list = list(word)\n",
        "        size = self.seq_size\n",
        "\n",
        "        # padding\n",
        "        for i in range(size):\n",
        "            word.insert(0, MarkovChain.START_TOKEN)\n",
        "        \n",
        "        for i in range(len(word)-size):\n",
        "            yield tuple(word[i:i+size+1])"
      ],
      "metadata": {
        "id": "SEMauoZ_dKAQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MarkovChainLight:\n",
        "    START_TOKEN = \" \"\n",
        "    \n",
        "    def __init__(self, text: str, sequence_size:int):\n",
        "        \"\"\"\n",
        "        Markov chain allows us to predict the next element of a sequence based\n",
        "         on the current state. Here we predict the next character based of a\n",
        "         given sequence of characters.\n",
        "        \n",
        "        parameters:\n",
        "            text:          one string that contains the whole text on which the chain\n",
        "                            is going to be based\n",
        "            sequence_size: to predict the next element we take into account the last N\n",
        "                            elements of a given sequence. This parameter is the N.\n",
        "        \"\"\"\n",
        "        self.seq_size = sequence_size\n",
        "        self.text = text\n",
        "        self.corpus = [text]\n",
        "        self.all_chars = sorted(list(set(''.join(self.corpus)) - set(whitespace)))\n",
        "        self.char_to_id = self.__char_to_id__()\n",
        "        self.id_to_char = {v: k for k, v in self.char_to_id.items()}\n",
        "        self.M = self.__coocurrance_matrix__()\n",
        "        \n",
        "    def predict_next_char(self, chars) -> str:\n",
        "        assert len(chars) == self.seq_size\n",
        "        \n",
        "        id_tupl = tuple([self.char_to_id[char] for char in chars])\n",
        "        next_id: int = np.argmax(self.M[id_tupl])\n",
        "        if next_id == 0:\n",
        "            # Every char has equal probability, most possibly 0, and <END> tag is returned\n",
        "            return None \n",
        "        next_char: str = self.id_to_char[next_id]\n",
        "        return next_char\n",
        "        \n",
        "    def proba(self, prev, next_) -> float:\n",
        "        \n",
        "        try:\n",
        "          assert len(prev) == self.seq_size\n",
        "          assert next_ in self.char_to_id\n",
        "          id_tupl = tuple([self.char_to_id[char] for char in prev])\n",
        "          next_id = self.char_to_id[next_]\n",
        "          proba = self.M[id_tupl][next_id]\n",
        "        except:\n",
        "          proba = 0\n",
        "        return proba\n",
        "    \n",
        "    def normalize(self):\n",
        "        tokens = [t.text.strip(punctuation) for t in tokenize(self.text)]\n",
        "        return [t for t in tokens if len(t) > 0]\n",
        "    \n",
        "    def __coocurrance_matrix__(self):\n",
        "        M = np.zeros(tuple(\n",
        "                    [len(self.char_to_id)] * (self.seq_size+1)\n",
        "                 ))\n",
        "        for word in self.corpus:\n",
        "            # srez has size `self.seq_size` + 1\n",
        "            for srez in self.__char_groups__(word):\n",
        "                ids = tuple([self.char_to_id[char] for char in srez])\n",
        "                M[ids] += 1\n",
        "        return M\n",
        "                \n",
        "        \n",
        "    def __char_to_id__(self):\n",
        "        char_to_id = {\n",
        "            MarkovChainLight.START_TOKEN: 0,\n",
        "        }\n",
        "        for i, char in enumerate(self.all_chars):\n",
        "            i += 2\n",
        "            char_to_id[char] = i\n",
        "        return char_to_id\n",
        "        \n",
        "    def __char_groups__(self, word):\n",
        "        word: list = list(word)\n",
        "        size = self.seq_size\n",
        "\n",
        "        # padding\n",
        "        for i in range(size):\n",
        "            word.insert(0, MarkovChainLight.START_TOKEN)\n",
        "        \n",
        "        for i in range(len(word)-size):\n",
        "            yield tuple(word[i:i+size+1])"
      ],
      "metadata": {
        "id": "EITq8Ro2AiAG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Предсказание"
      ],
      "metadata": {
        "id": "DYSgzcWrW8MB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Лучшая модель, её датасет"
      ],
      "metadata": {
        "id": "Y9iFbRkIH2ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/models/cnn_podelka_65ep.pt\"\n",
        "double_conv_model_with_scheduling = torch.nn.Sequential(\n",
        "  torch.nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5),\n",
        "  torch.nn.ReLU(),\n",
        "  torch.nn.MaxPool2d(kernel_size=2),\n",
        "  torch.nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5),\n",
        "  torch.nn.ReLU(),\n",
        "  torch.nn.MaxPool2d(kernel_size=2),\n",
        "  torch.nn.Flatten(),\n",
        "  torch.nn.Linear(1620, 512),\n",
        "  torch.nn.ReLU(),\n",
        "  torch.nn.Linear(512, 36),\n",
        "  )\n",
        "best_model = load_custom_model_from_pt(model_path, double_conv_model_with_scheduling, device)\n",
        "\n",
        "# model_path = \"/content/drive/MyDrive/models/cnn_podelka_cropped_chars.pt\"\n",
        "# double_conv_model_with_scheduling = torch.nn.Sequential(\n",
        "#   torch.nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5),\n",
        "#   torch.nn.ReLU(),\n",
        "#   torch.nn.MaxPool2d(kernel_size=2),\n",
        "#   torch.nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5),\n",
        "#   torch.nn.ReLU(),\n",
        "#   torch.nn.MaxPool2d(kernel_size=2),\n",
        "#   torch.nn.Flatten(),\n",
        "#   torch.nn.Linear(1620, 512),\n",
        "#   torch.nn.ReLU(),\n",
        "#   torch.nn.Linear(512, 54),\n",
        "#   )\n",
        "# best_model = load_custom_model_from_pt(model_path, double_conv_model_with_scheduling, device)"
      ],
      "metadata": {
        "id": "eMNZUTBtH2BN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = Compose(\n",
        "        [\n",
        "            Resize((50, 50)), \n",
        "            # RandomAffine(degrees=15),\n",
        "            ToTensor(),\n",
        "            # RandomErasing(inplace=True),\n",
        "            Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                      std=[0.229, 0.224, 0.225])\n",
        "        ]\n",
        "    )\n",
        "dataset = ImageFolder(\n",
        "    \"./dataset_more_data\", \n",
        "    transform=transform\n",
        ")\n",
        "class_names = list(dataset.class_to_idx.keys())\n",
        "classes = {v: k for k,v in dataset.class_to_idx.items()}\n",
        "print(class_names)\n",
        "\n",
        "# transform = Compose(\n",
        "#         [\n",
        "#             Resize((50, 50)), \n",
        "#             # RandomAffine(degrees=15),\n",
        "#             ToTensor(), \n",
        "#             # RandomErasing(inplace=True),\n",
        "#             # Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#             #           std=[0.229, 0.224, 0.225]),\n",
        "#             RandomErasing(value=(-255,-255,-255), ratio=(.3, .4), scale=(.1, .1)),\n",
        "#         ]\n",
        "#     )\n",
        "# dataset = ImageFolder(\n",
        "#     \"./dataset_cropped_chars\", \n",
        "#     transform=transform\n",
        "# )\n",
        "\n",
        "# class_names = list(dataset.class_to_idx.keys())\n",
        "# classes = {v: k for k,v in dataset.class_to_idx.items()}\n",
        "# print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCxL2K1QIY_L",
        "outputId": "162f1815-6e50-4780-8d01-b7efc91aecb5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dash', 'e_mark', 'q_mark', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Непосредственно предсказание"
      ],
      "metadata": {
        "id": "tFG-cEk2H2vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Скользящее окно. Поскользнулось и не работает"
      ],
      "metadata": {
        "id": "3QrIcCntBM1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_word_with_incremental_window(\n",
        "    path,\n",
        "    classifier,\n",
        "    chain,\n",
        "    dataset,\n",
        "    device,\n",
        "    window_min_size=15,\n",
        "    window_max_size=50,\n",
        "    window_growth_step=5,\n",
        "    window_slide_step=5,\n",
        "    markov_threshold: float = 0.,\n",
        "    save_img: bool = False,\n",
        "    save_path: bool = None):\n",
        "  \"\"\"\n",
        "  Sliding window goes through the image located at `path`. It is defined by its \n",
        "    leftmost position and its size, i.e. how far right it spans. \n",
        "  With each attempt at recognition of a letter the window will grow from `window_min_size` to `window_max_size` with step `window_growth_step`\n",
        "    until it either successfully predicts a letter or can grow no more.\n",
        "  Either the probability of prediction must be >= `classification_threshold`,\n",
        "      or the probability of this letter being a continuation of the previous sequence must be >= `markov_threshold`.\n",
        "\n",
        "  Parameters:\n",
        "    path: path to an image of a word\n",
        "    classifier: sklearn classifier or anything that has same interface for prediction\n",
        "    chain: Markov chain to evaluate, how well the predicted char fits in the previous sequence.\n",
        "    dataset: pytorch dataset. Is used to take classes and transform object from it\n",
        "    device: cuda or cpu\n",
        "    window_min_size: the starting width of a sliding window\n",
        "    window_max_size: the max width of a sliding window.\n",
        "    window_growth_step: how much a sliding window grows if no char was recognised for current size. \n",
        "                        Window never grows beyond `window_max_size` or the width of the image.\n",
        "    window_slide_step: the step of a sliding window, like a stride in a CNN\n",
        "    classification_threshold: how high must the probability of prediction be qualify for a valid classification\n",
        "    markov_threshold: how high must the probability of a letter-sequence be to qualify for a valid sequence\n",
        "    save_img: whether the content of the window is saved, given that the prediction probability surpasses the thresholds\n",
        "  \"\"\"\n",
        "  assert window_min_size <= window_max_size\n",
        "  transform = dataset.transform\n",
        "  classes = {v: k for k,v in dataset.class_to_idx.items()}\n",
        "  word_img = Image.open(path)\n",
        "  width,height= word_img.size\n",
        "\n",
        "  if width < window_min_size:\n",
        "    # if the image is very small, we will inspect it once and hope for the best\n",
        "    window_min_size = width\n",
        "\n",
        "  # left border of a window \n",
        "  position = 0\n",
        "  # initial padding for markov chain\n",
        "  inferred = [MarkovChain.START_TOKEN] * chain.seq_size\n",
        "  pics = []\n",
        "  while position <= width - window_min_size:\n",
        "    window_size = window_min_size\n",
        "    success = False\n",
        "\n",
        "    while window_size <= window_max_size and position + window_size <= width:\n",
        "      # print(f\"Infering {path}. Position: {position}, window size: {window_size}\")\n",
        "      l, r = position, position + window_size \n",
        "      window = word_img.crop((l,0,r,height))\n",
        "      pad_size = 5 ## (BASE_WIDTH-window.width)//2\n",
        "      resized = preprocess(\n",
        "          window,\n",
        "          padding=10,\n",
        "          min_contour=30,\n",
        "          deacrease_contour_if_none=True,\n",
        "      )      \n",
        "      letter = predict_image(classifier, classes, resized, transform, \"cpu\")\n",
        "      markov_sure = chain.proba(inferred[-chain.seq_size:], next_=letter) >= markov_threshold\n",
        "      if markov_sure:\n",
        "        # print(f\"COOL! Infered {letter}. Position: {position}, window size: {window_size}. Markov: {markov_sure}, Predictor: {predictor_sure}\")\n",
        "        success = True\n",
        "        inferred.append(letter)\n",
        "        pics.append(resized)\n",
        "        if save_img and save_path is not None:\n",
        "          path_prefix = f\"{save_path}/{letter}\"\n",
        "          os.makedirs(path_prefix, exist_ok=True)\n",
        "          target_loc = next_path(path_pattern=f\"{path_prefix}/{letter}-%s.jpg\")\n",
        "          window.save(target_loc)\n",
        "        break\n",
        "      else:\n",
        "        window_size += window_growth_step\n",
        "    if success is True:\n",
        "      # this window contained a letter, so we can go further for its whole width\n",
        "      position += window_size\n",
        "    else:\n",
        "      position += window_slide_step\n",
        "  return pics, inferred[chain.seq_size:]#''.join(inferred[chain.seq_size:])"
      ],
      "metadata": {
        "id": "K4FWLrW7BMAK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(\"dictation_text.txt\").read().lower()\n",
        "chain = MarkovChain(sequence_size=3,text=text)\n",
        "# 57347_16 хороший почерк\n",
        "words = glob(\"./words/57347_16/**/*.jpg\", recursive=True)\n",
        "print(words)\n",
        "word = words[26]\n",
        "word_img = Image.open(word)\n",
        "word_img"
      ],
      "metadata": {
        "id": "Fdk_viylB-ug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "459f5d38-4cbc-4fbc-cd1f-9f9110773c55"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./words/57347_16/57347_16-0/12/2.jpg', './words/57347_16/57347_16-0/12/5.jpg', './words/57347_16/57347_16-0/12/0.jpg', './words/57347_16/57347_16-0/12/3.jpg', './words/57347_16/57347_16-0/12/4.jpg', './words/57347_16/57347_16-0/12/1.jpg', './words/57347_16/57347_16-0/12/6.jpg', './words/57347_16/57347_16-0/21/2.jpg', './words/57347_16/57347_16-0/21/0.jpg', './words/57347_16/57347_16-0/21/3.jpg', './words/57347_16/57347_16-0/21/4.jpg', './words/57347_16/57347_16-0/21/1.jpg', './words/57347_16/57347_16-0/19/2.jpg', './words/57347_16/57347_16-0/19/0.jpg', './words/57347_16/57347_16-0/19/3.jpg', './words/57347_16/57347_16-0/19/4.jpg', './words/57347_16/57347_16-0/19/1.jpg', './words/57347_16/57347_16-0/1/2.jpg', './words/57347_16/57347_16-0/1/5.jpg', './words/57347_16/57347_16-0/1/0.jpg', './words/57347_16/57347_16-0/1/3.jpg', './words/57347_16/57347_16-0/1/4.jpg', './words/57347_16/57347_16-0/1/1.jpg', './words/57347_16/57347_16-0/1/6.jpg', './words/57347_16/57347_16-0/1/7.jpg', './words/57347_16/57347_16-0/14/2.jpg', './words/57347_16/57347_16-0/14/0.jpg', './words/57347_16/57347_16-0/14/3.jpg', './words/57347_16/57347_16-0/14/1.jpg', './words/57347_16/57347_16-0/25/2.jpg', './words/57347_16/57347_16-0/25/0.jpg', './words/57347_16/57347_16-0/25/3.jpg', './words/57347_16/57347_16-0/25/4.jpg', './words/57347_16/57347_16-0/25/1.jpg', './words/57347_16/57347_16-0/6/2.jpg', './words/57347_16/57347_16-0/6/0.jpg', './words/57347_16/57347_16-0/6/3.jpg', './words/57347_16/57347_16-0/6/1.jpg', './words/57347_16/57347_16-0/2/2.jpg', './words/57347_16/57347_16-0/2/0.jpg', './words/57347_16/57347_16-0/2/3.jpg', './words/57347_16/57347_16-0/2/4.jpg', './words/57347_16/57347_16-0/2/1.jpg', './words/57347_16/57347_16-0/18/2.jpg', './words/57347_16/57347_16-0/18/0.jpg', './words/57347_16/57347_16-0/18/3.jpg', './words/57347_16/57347_16-0/18/4.jpg', './words/57347_16/57347_16-0/18/1.jpg', './words/57347_16/57347_16-0/10/2.jpg', './words/57347_16/57347_16-0/10/5.jpg', './words/57347_16/57347_16-0/10/0.jpg', './words/57347_16/57347_16-0/10/3.jpg', './words/57347_16/57347_16-0/10/4.jpg', './words/57347_16/57347_16-0/10/1.jpg', './words/57347_16/57347_16-0/0/0.jpg', './words/57347_16/57347_16-0/27/2.jpg', './words/57347_16/57347_16-0/27/0.jpg', './words/57347_16/57347_16-0/27/3.jpg', './words/57347_16/57347_16-0/27/4.jpg', './words/57347_16/57347_16-0/27/1.jpg', './words/57347_16/57347_16-0/26/2.jpg', './words/57347_16/57347_16-0/26/5.jpg', './words/57347_16/57347_16-0/26/0.jpg', './words/57347_16/57347_16-0/26/3.jpg', './words/57347_16/57347_16-0/26/4.jpg', './words/57347_16/57347_16-0/26/1.jpg', './words/57347_16/57347_16-0/26/6.jpg', './words/57347_16/57347_16-0/11/2.jpg', './words/57347_16/57347_16-0/11/5.jpg', './words/57347_16/57347_16-0/11/0.jpg', './words/57347_16/57347_16-0/11/3.jpg', './words/57347_16/57347_16-0/11/4.jpg', './words/57347_16/57347_16-0/11/1.jpg', './words/57347_16/57347_16-0/20/2.jpg', './words/57347_16/57347_16-0/20/0.jpg', './words/57347_16/57347_16-0/20/3.jpg', './words/57347_16/57347_16-0/20/4.jpg', './words/57347_16/57347_16-0/20/1.jpg', './words/57347_16/57347_16-0/22/2.jpg', './words/57347_16/57347_16-0/22/5.jpg', './words/57347_16/57347_16-0/22/0.jpg', './words/57347_16/57347_16-0/22/3.jpg', './words/57347_16/57347_16-0/22/4.jpg', './words/57347_16/57347_16-0/22/1.jpg', './words/57347_16/57347_16-0/9/2.jpg', './words/57347_16/57347_16-0/9/5.jpg', './words/57347_16/57347_16-0/9/0.jpg', './words/57347_16/57347_16-0/9/3.jpg', './words/57347_16/57347_16-0/9/4.jpg', './words/57347_16/57347_16-0/9/1.jpg', './words/57347_16/57347_16-0/9/6.jpg', './words/57347_16/57347_16-0/9/7.jpg', './words/57347_16/57347_16-0/23/2.jpg', './words/57347_16/57347_16-0/23/0.jpg', './words/57347_16/57347_16-0/23/1.jpg', './words/57347_16/57347_16-0/15/2.jpg', './words/57347_16/57347_16-0/15/5.jpg', './words/57347_16/57347_16-0/15/0.jpg', './words/57347_16/57347_16-0/15/3.jpg', './words/57347_16/57347_16-0/15/4.jpg', './words/57347_16/57347_16-0/15/1.jpg', './words/57347_16/57347_16-0/15/6.jpg', './words/57347_16/57347_16-0/7/2.jpg', './words/57347_16/57347_16-0/7/0.jpg', './words/57347_16/57347_16-0/7/3.jpg', './words/57347_16/57347_16-0/7/4.jpg', './words/57347_16/57347_16-0/7/1.jpg', './words/57347_16/57347_16-0/4/2.jpg', './words/57347_16/57347_16-0/4/5.jpg', './words/57347_16/57347_16-0/4/0.jpg', './words/57347_16/57347_16-0/4/3.jpg', './words/57347_16/57347_16-0/4/4.jpg', './words/57347_16/57347_16-0/4/1.jpg', './words/57347_16/57347_16-0/16/2.jpg', './words/57347_16/57347_16-0/16/0.jpg', './words/57347_16/57347_16-0/16/3.jpg', './words/57347_16/57347_16-0/16/4.jpg', './words/57347_16/57347_16-0/16/1.jpg', './words/57347_16/57347_16-0/8/2.jpg', './words/57347_16/57347_16-0/8/5.jpg', './words/57347_16/57347_16-0/8/0.jpg', './words/57347_16/57347_16-0/8/3.jpg', './words/57347_16/57347_16-0/8/4.jpg', './words/57347_16/57347_16-0/8/1.jpg', './words/57347_16/57347_16-0/13/2.jpg', './words/57347_16/57347_16-0/13/0.jpg', './words/57347_16/57347_16-0/13/3.jpg', './words/57347_16/57347_16-0/13/4.jpg', './words/57347_16/57347_16-0/13/1.jpg', './words/57347_16/57347_16-0/29/2.jpg', './words/57347_16/57347_16-0/29/5.jpg', './words/57347_16/57347_16-0/29/0.jpg', './words/57347_16/57347_16-0/29/3.jpg', './words/57347_16/57347_16-0/29/4.jpg', './words/57347_16/57347_16-0/29/1.jpg', './words/57347_16/57347_16-0/3/2.jpg', './words/57347_16/57347_16-0/3/5.jpg', './words/57347_16/57347_16-0/3/0.jpg', './words/57347_16/57347_16-0/3/3.jpg', './words/57347_16/57347_16-0/3/4.jpg', './words/57347_16/57347_16-0/3/1.jpg', './words/57347_16/57347_16-0/28/2.jpg', './words/57347_16/57347_16-0/28/5.jpg', './words/57347_16/57347_16-0/28/0.jpg', './words/57347_16/57347_16-0/28/3.jpg', './words/57347_16/57347_16-0/28/4.jpg', './words/57347_16/57347_16-0/28/1.jpg', './words/57347_16/57347_16-0/28/6.jpg', './words/57347_16/57347_16-0/17/2.jpg', './words/57347_16/57347_16-0/17/0.jpg', './words/57347_16/57347_16-0/17/3.jpg', './words/57347_16/57347_16-0/17/4.jpg', './words/57347_16/57347_16-0/17/1.jpg', './words/57347_16/57347_16-0/5/2.jpg', './words/57347_16/57347_16-0/5/5.jpg', './words/57347_16/57347_16-0/5/0.jpg', './words/57347_16/57347_16-0/5/3.jpg', './words/57347_16/57347_16-0/5/4.jpg', './words/57347_16/57347_16-0/5/1.jpg', './words/57347_16/57347_16-0/5/6.jpg', './words/57347_16/57347_16-0/24/2.jpg', './words/57347_16/57347_16-0/24/5.jpg', './words/57347_16/57347_16-0/24/0.jpg', './words/57347_16/57347_16-0/24/3.jpg', './words/57347_16/57347_16-0/24/4.jpg', './words/57347_16/57347_16-0/24/1.jpg', './words/57347_16/57347_16-1/12/2.jpg', './words/57347_16/57347_16-1/12/5.jpg', './words/57347_16/57347_16-1/12/0.jpg', './words/57347_16/57347_16-1/12/3.jpg', './words/57347_16/57347_16-1/12/4.jpg', './words/57347_16/57347_16-1/12/1.jpg', './words/57347_16/57347_16-1/21/0.jpg', './words/57347_16/57347_16-1/21/1.jpg', './words/57347_16/57347_16-1/19/2.jpg', './words/57347_16/57347_16-1/19/5.jpg', './words/57347_16/57347_16-1/19/0.jpg', './words/57347_16/57347_16-1/19/3.jpg', './words/57347_16/57347_16-1/19/1.jpg', './words/57347_16/57347_16-1/19/6.jpg', './words/57347_16/57347_16-1/1/2.jpg', './words/57347_16/57347_16-1/1/5.jpg', './words/57347_16/57347_16-1/1/0.jpg', './words/57347_16/57347_16-1/1/3.jpg', './words/57347_16/57347_16-1/1/4.jpg', './words/57347_16/57347_16-1/1/1.jpg', './words/57347_16/57347_16-1/14/2.jpg', './words/57347_16/57347_16-1/14/5.jpg', './words/57347_16/57347_16-1/14/0.jpg', './words/57347_16/57347_16-1/14/4.jpg', './words/57347_16/57347_16-1/14/1.jpg', './words/57347_16/57347_16-1/6/2.jpg', './words/57347_16/57347_16-1/6/5.jpg', './words/57347_16/57347_16-1/6/0.jpg', './words/57347_16/57347_16-1/6/3.jpg', './words/57347_16/57347_16-1/6/4.jpg', './words/57347_16/57347_16-1/6/1.jpg', './words/57347_16/57347_16-1/2/2.jpg', './words/57347_16/57347_16-1/2/5.jpg', './words/57347_16/57347_16-1/2/0.jpg', './words/57347_16/57347_16-1/2/3.jpg', './words/57347_16/57347_16-1/2/4.jpg', './words/57347_16/57347_16-1/2/1.jpg', './words/57347_16/57347_16-1/18/2.jpg', './words/57347_16/57347_16-1/18/0.jpg', './words/57347_16/57347_16-1/18/3.jpg', './words/57347_16/57347_16-1/18/4.jpg', './words/57347_16/57347_16-1/18/1.jpg', './words/57347_16/57347_16-1/10/2.jpg', './words/57347_16/57347_16-1/10/5.jpg', './words/57347_16/57347_16-1/10/0.jpg', './words/57347_16/57347_16-1/10/3.jpg', './words/57347_16/57347_16-1/10/4.jpg', './words/57347_16/57347_16-1/10/1.jpg', './words/57347_16/57347_16-1/0/2.jpg', './words/57347_16/57347_16-1/0/5.jpg', './words/57347_16/57347_16-1/0/0.jpg', './words/57347_16/57347_16-1/0/3.jpg', './words/57347_16/57347_16-1/0/4.jpg', './words/57347_16/57347_16-1/0/1.jpg', './words/57347_16/57347_16-1/0/6.jpg', './words/57347_16/57347_16-1/11/2.jpg', './words/57347_16/57347_16-1/11/0.jpg', './words/57347_16/57347_16-1/11/3.jpg', './words/57347_16/57347_16-1/11/1.jpg', './words/57347_16/57347_16-1/20/2.jpg', './words/57347_16/57347_16-1/20/5.jpg', './words/57347_16/57347_16-1/20/0.jpg', './words/57347_16/57347_16-1/20/3.jpg', './words/57347_16/57347_16-1/20/9.jpg', './words/57347_16/57347_16-1/20/8.jpg', './words/57347_16/57347_16-1/20/4.jpg', './words/57347_16/57347_16-1/20/6.jpg', './words/57347_16/57347_16-1/20/7.jpg', './words/57347_16/57347_16-1/9/2.jpg', './words/57347_16/57347_16-1/9/0.jpg', './words/57347_16/57347_16-1/9/3.jpg', './words/57347_16/57347_16-1/9/1.jpg', './words/57347_16/57347_16-1/15/0.jpg', './words/57347_16/57347_16-1/7/2.jpg', './words/57347_16/57347_16-1/7/5.jpg', './words/57347_16/57347_16-1/7/0.jpg', './words/57347_16/57347_16-1/7/3.jpg', './words/57347_16/57347_16-1/7/4.jpg', './words/57347_16/57347_16-1/7/1.jpg', './words/57347_16/57347_16-1/4/2.jpg', './words/57347_16/57347_16-1/4/0.jpg', './words/57347_16/57347_16-1/4/3.jpg', './words/57347_16/57347_16-1/4/4.jpg', './words/57347_16/57347_16-1/4/1.jpg', './words/57347_16/57347_16-1/16/0.jpg', './words/57347_16/57347_16-1/16/1.jpg', './words/57347_16/57347_16-1/8/2.jpg', './words/57347_16/57347_16-1/8/0.jpg', './words/57347_16/57347_16-1/8/3.jpg', './words/57347_16/57347_16-1/8/1.jpg', './words/57347_16/57347_16-1/13/2.jpg', './words/57347_16/57347_16-1/13/0.jpg', './words/57347_16/57347_16-1/13/3.jpg', './words/57347_16/57347_16-1/13/4.jpg', './words/57347_16/57347_16-1/13/1.jpg', './words/57347_16/57347_16-1/3/2.jpg', './words/57347_16/57347_16-1/3/0.jpg', './words/57347_16/57347_16-1/3/3.jpg', './words/57347_16/57347_16-1/3/1.jpg', './words/57347_16/57347_16-1/17/2.jpg', './words/57347_16/57347_16-1/17/5.jpg', './words/57347_16/57347_16-1/17/3.jpg', './words/57347_16/57347_16-1/17/4.jpg', './words/57347_16/57347_16-1/17/1.jpg', './words/57347_16/57347_16-1/17/6.jpg', './words/57347_16/57347_16-1/5/2.jpg', './words/57347_16/57347_16-1/5/0.jpg', './words/57347_16/57347_16-1/5/1.jpg']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=83x50 at 0x7F06EF2F7590>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed = parse_word_with_incremental_window(\n",
        "  path=word,\n",
        "  classifier=best_model,\n",
        "  chain=chain,\n",
        "  dataset=dataset,\n",
        "  device=device,\n",
        "  markov_threshold=0.05,\n",
        "  window_min_size=10\n",
        ")\n",
        "parsed"
      ],
      "metadata": {
        "id": "YHYkImINCAJo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "ac4acd7b-782b-4035-c5cf-b03329aad38f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-00e4e4edc8bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmarkov_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mwindow_min_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-f84240244dea>\u001b[0m in \u001b[0;36mparse_word_with_incremental_window\u001b[0;34m(path, classifier, chain, dataset, device, window_min_size, window_max_size, window_growth_step, window_slide_step, markov_threshold, save_img, save_path)\u001b[0m\n\u001b[1;32m     63\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m           \u001b[0mmin_contour\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m           \u001b[0mdeacrease_contour_if_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m       )      \n\u001b[1;32m     67\u001b[0m       \u001b[0mletter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1551dd60d22b>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(image, min_contour, padding, deacrease_contour_if_none)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0monly_large_countour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelete_bad_contour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_contour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mboxed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mput_in_a_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_large_countour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mboxed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdeacrease_contour_if_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0mmin_contour\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-777a4ffe1381>\u001b[0m in \u001b[0;36mput_in_a_box\u001b[0;34m(char)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_border\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_border\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfind_border\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mbottom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfind_border\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ещё что-то"
      ],
      "metadata": {
        "id": "ePQ4TABoBMnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) \"Большое\" слово не может состоять из букв. Можно посчитать среднюю длину символа L пикселей: и рассчитывать, что слово, состоящее из `N*L +- e` состоит из N символов с погрешностью в пикселях e.\n",
        "\n",
        "2) Граница буквы в любом случае пролегает там, где в колонке содержится 1 пиксель\n",
        "\n",
        "3) Каждое новое слово - продолжение предыдущего: либо его часть, либо следует за ним в диктанте. Можно натравить марковскую цепь на это, т.е. предыдущие три символа - это не теги начала слова, а две буквы предыдущего слова и пробел."
      ],
      "metadata": {
        "id": "IPkRrNlGCPC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# def predict_word(\n",
        "#     word: Image,\n",
        "#     chain: MarkovChainLight,\n",
        "#     window_min_size: int,\n",
        "#     window_max_size: int,\n",
        "#     window_slide_step: int,\n",
        "#     window_growth_step: int):\n",
        "#   PAD = 5\n",
        "#   MIN_CONTOUR = 40\n",
        "#   predicted = [chain.__class__.START_TOKEN] * chain.seq_size\n",
        "#   images = []\n",
        "#   window_max_size = min(word.width, window_max_size)\n",
        "#   window = [0, 0, min(window_min_size,window_max_size), word.height]\n",
        "#   # цикл для прохода по слову\n",
        "#   while window[2] <= word.width:\n",
        "#     # проверка на то, что правая граница окна не проходит через \"закрытую\" букву типа о,а,б,в. \n",
        "#     print(f\"Validating window {window}.\", end=\" \")\n",
        "#     while window[2] - window[0] < window_max_size and window[2] < word.width:\n",
        "#       image = word.crop(window)\n",
        "#       preprocessed = preprocess(\n",
        "#         image,\n",
        "#         padding=PAD,\n",
        "#         min_contour=MIN_CONTOUR,\n",
        "#         deacrease_contour_if_none=True,\n",
        "#       )\n",
        "#       plt.imshow(word)\n",
        "#       if window_is_valid(preprocessed, PAD):\n",
        "#         print(f\" Valid! \")\n",
        "#         break\n",
        "#       else:\n",
        "#         window[2] += 1\n",
        "#         print(f\" -> {window}\", end=\" \")\n",
        "#     # цикл для изменения скользящего окна\n",
        "#     while window[2] - window[0] <= window_max_size and window[2] <= word.width:\n",
        "#       #trying to predict\n",
        "#       # classes, best_model и transform берутся из среды!\n",
        "#       letter = predict_image(best_model, classes, preprocessed, transform, \"cpu\")\n",
        "\n",
        "#       if chain.proba(predicted[-chain.seq_size:], letter) > 0:\n",
        "#         print(f\"Predicted {letter} in {window}.\", end=\" \")\n",
        "#         predicted.append(letter)\n",
        "#         images.append(image)\n",
        "#         window[0] = window[2]\n",
        "#         window[2] += window_min_size\n",
        "#         print(f\"Window is now {window}\")\n",
        "#         break\n",
        "#       else:\n",
        "#         window[2] += window_growth_step\n",
        "#         print(f\"Prediction '{letter}' given context '{predicted[-chain.seq_size:]}' did not satisfy the chain. Window increased to {window}\")\n",
        "#     # только если окно разрослось, но так и не получилось ничего распознать\n",
        "#     else:\n",
        "#       window[0] += window_slide_step\n",
        "#       window[2] = window[0] + window_min_size\n",
        "#   return images, predicted[chain.seq_size:]"
      ],
      "metadata": {
        "id": "utL50wudcsJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_average_symbol_width(words: \"List[Image]\") -> float:\n",
        "  return sum(map(lambda image: image.width, words)) / total_characters\n",
        "\n",
        "def open_images(paths):\n",
        "  words = []\n",
        "  for each in paths:\n",
        "    words.append(Image.open(each))\n",
        "  return words\n",
        "\n",
        "def window_is_valid(pil_image, pad):\n",
        "  im = img_as_bool(binarize(pil_image))\n",
        "  im = thin(binary_closing(skeletonize(im)))\n",
        "  if pad:\n",
        "    im = im[pad:-pad, pad:-pad]\n",
        "  return im[:, -1].sum() < 2\n",
        "\n",
        "def create_valid_window(window: \"list[int]\",\n",
        "                        word_img: Image,\n",
        "                        window_max_size: int,\n",
        "                        PAD: int,\n",
        "                        MIN_CONTOUR: int):\n",
        "  \"\"\" ИЗМЕНЯЕТ ИЗНАЧАЛЬНЫЙ МАССИВ В КАЧЕСТВЕ САЙД ЭФФЕКТА \"\"\"\n",
        "  # расширяем окно, чтобы правая граница не проходила через \"закрытую\" букву типа о,а,б,в. \n",
        "  # в случае с такими буквами это позволяет провести правую границу окна через соединение с соседней буквой\n",
        "  while window[2] - window[0] <= window_max_size and window[2] <= word_img.width:\n",
        "    image = word_img.crop(window)\n",
        "    preprocessed = preprocess(\n",
        "      image,\n",
        "      padding=PAD,\n",
        "      min_contour=MIN_CONTOUR,\n",
        "      deacrease_contour_if_none=True,\n",
        "    )\n",
        "    if window_is_valid(preprocessed, PAD):\n",
        "      break\n",
        "    else:\n",
        "      window[2] += 1\n",
        "  try:\n",
        "    return image, preprocessed\n",
        "  except Exception as e:\n",
        "    # plt.imshow(word_img)\n",
        "    # print(\"window, window_max_size, word_width\")\n",
        "    # print(window, window_max_size, word_img.width)\n",
        "    # raise e\n",
        "    pass\n",
        "  \n",
        "\n",
        "def predict_word_with_fallback(\n",
        "    word: Image,\n",
        "    chain: MarkovChainLight,\n",
        "    average_char_width: int,\n",
        "    window_min_size: int,\n",
        "    window_max_size: int,\n",
        "    window_slide_step: int,\n",
        "    window_growth_step: int):\n",
        "  PAD = 5\n",
        "  MIN_CONTOUR = 40\n",
        "  MAX_CONSECUTIVE_WINDOW_SLIDES = 3\n",
        "\n",
        "  LEVENSTEIN_TOLERANCE = 1\n",
        "  best_images = []\n",
        "  best_letters = []\n",
        "\n",
        "  # рекурсия для продвижения окна по слову с возможностью возвратиться в предыдущее состояние (вернувишь в контекст предыдущего вызова)\n",
        "  def parse_word_rec(\n",
        "      word_img: Image,\n",
        "      accum_letters: \"list[str]\",\n",
        "      accum_images = [],\n",
        "      slides = 0\n",
        "      ):\n",
        "    accum_letters_as_str = ''.join(accum_letters[chain.seq_size:])\n",
        "    # print(f\"Parsing image of shape {word_img.size}. Letters so far: {accum_letters_as_str}\")\n",
        "    # base case 1: успех\n",
        "    if word.width * 0.8 <= average_char_width * len(accum_letters_as_str) <= word.width * 1.2and\\\n",
        "        accum_letters_as_str in corpus:\n",
        "      return accum_images, accum_letters[chain.seq_size:], True\n",
        "\n",
        "    # base case 2: почти успех. Сохраним в переменные, потом вернём в случае неудачи\n",
        "    elif word.width * 0.8 <= average_char_width * len(accum_letters_as_str) <= word.width * 1.2 and\\\n",
        "        any(map(lambda x: levenshtein_distance(x, accum_letters_as_str) <= LEVENSTEIN_TOLERANCE, corpus)):\n",
        "      nonlocal best_images\n",
        "      nonlocal best_letters\n",
        "      best_images = accum_images\n",
        "      best_letters = accum_letters[chain.seq_size:]\n",
        "\n",
        "    # base case 3: позорный провал\n",
        "    if word_img.width < window_min_size or slides >= MAX_CONSECUTIVE_WINDOW_SLIDES:\n",
        "      return accum_images, accum_letters, False\n",
        "\n",
        "    # recursive case \n",
        "    successfuly_parsed_word = False\n",
        "    window = [0, 0, window_min_size, word_img.height]\n",
        "    max_window = min(window_max_size, word_img.width)\n",
        "    # в цикле окно растёт, пока не достигнет границы картинки или максимального размера\n",
        "    while window[2] - window[0] <= max_window and window[2] <= word.width:\n",
        "      # window изменяется внутри вызова `create_valid_window`. Чтобы избежать вычислений с заведомо неверным окошком\n",
        "      image, preprocessed = create_valid_window(window, word_img, max_window, PAD, MIN_CONTOUR)\n",
        "      # Распознавание. Переменные classes, best_model и transform берутся из среды!\n",
        "      letter = predict_image(best_model, classes, preprocessed, transform, \"cpu\")\n",
        "\n",
        "      # Если цепь Маркова одобрила результат распознавания\n",
        "      if chain.proba(accum_letters[-chain.seq_size:], letter) > 0:\n",
        "        # То углубимся в рекурсию, вырезав из word_img окошко с успешно распознанным символом.\n",
        "        # print(f\"Detected {letter} in {window}. Image of shape {word_img.size}\")\n",
        "        parsed_images, parsed_prediction, successfuly_parsed_word = parse_word_rec(\n",
        "            word_img.crop((window[2], 0, word_img.width, word_img.height)),\n",
        "            accum_letters=accum_letters + [letter],\n",
        "            accum_images=accum_images + [image],\n",
        "            slides=0\n",
        "        )\n",
        "        # True, если удалось распознать слово из корпуса, которое ещё и подходящего размера\n",
        "        if successfuly_parsed_word:\n",
        "          break\n",
        "\n",
        "      # Либо цепь Маркова не одобрила результат\n",
        "      # Либо распознать слово в последующих вызовах не удалось.\n",
        "      # Продолжим изменять расположение текущего окошка (а значит и последующих)\n",
        "      window[2] += window_growth_step\n",
        "\n",
        "    # если окно разрослось, но так и не получилось ничего распознать\n",
        "    else:\n",
        "        parsed_images, parsed_prediction, successfuly_parsed_word = parse_word_rec(\n",
        "            word_img.crop((window_slide_step, 0, word_img.width, word_img.height)),\n",
        "            accum_letters=accum_letters,\n",
        "            accum_images=accum_images,\n",
        "            slides=slides+1\n",
        "        )\n",
        "    return parsed_images, parsed_prediction, successfuly_parsed_word\n",
        "    \n",
        "\n",
        "  # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
        "  parsed_images, parsed_prediction, successfuly_parsed_word = parse_word_rec(\n",
        "      word_img=word,\n",
        "      accum_letters=[chain.__class__.START_TOKEN] * chain.seq_size,\n",
        "  )\n",
        "  if successfuly_parsed_word:\n",
        "    return parsed_images, parsed_prediction, True\n",
        "  elif len(best_images) > 0 or len(best_letters) > 0:\n",
        "    return best_images, best_letters, True\n",
        "  else:\n",
        "    return parsed_images, parsed_prediction, False\n",
        "\n",
        "\n",
        "def recognition_another_try(\n",
        "    path_to_work: str,\n",
        "    chain: MarkovChainLight,\n",
        "    window_min_size=15,\n",
        "    window_max_size=45,\n",
        "    window_growth_step=5,\n",
        "    window_slide_step=5,\n",
        "    ):\n",
        "  words = glob(f\"{path_to_work}/**/*.jpg\", recursive=True)\n",
        "  words.sort(key=lambda path: int(path.split('/')[-1].replace(\".jpg\", \"\")))\n",
        "  words.sort(key=lambda path: int(path.split('/')[-2]))\n",
        "  words.sort(key=lambda path: int(path.split('/')[-3][-1]))\n",
        "  word_images = open_images(words)\n",
        "  average_char_width = calc_average_symbol_width(word_images)\n",
        "  tuples = []\n",
        "  for word in tqdm(word_images):\n",
        "    images, predicted, success = predict_word_with_fallback(\n",
        "        word,\n",
        "        chain,\n",
        "        average_char_width,\n",
        "        window_min_size,\n",
        "        window_max_size,\n",
        "        window_slide_step,\n",
        "        window_growth_step)\n",
        "    if success:\n",
        "      tuples.extend(zip(images, predicted))\n"
      ],
      "metadata": {
        "id": "jIUQwzfICKgb"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Демка"
      ],
      "metadata": {
        "id": "vVq_9PtiBzaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(\"dictation_text.txt\").read().lower()\n",
        "corpus = re.findall(\"[\\w]+\", text)\n",
        "text_cleared = ' '.join(corpus)\n",
        "total_characters = sum(map(len, corpus))\n",
        "total_characters\n",
        "chain = MarkovChain(sequence_size=3,text=text)\n",
        "# chain = MarkovChainLight(sequence_size=3,text=text_cleared)"
      ],
      "metadata": {
        "id": "G9oqIoXFHjLi"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 57347_16 хороший почерк\n",
        "words = glob(\"./words/57347_16/**/*.jpg\", recursive=True)\n",
        "words.sort(key=lambda path: int(path.split('/')[-1].replace(\".jpg\", \"\")))\n",
        "words.sort(key=lambda path: int(path.split('/')[-2]))\n",
        "words.sort(key=lambda path: int(path.split('/')[-3][-1]))\n",
        "word = words[0]\n",
        "word_img = Image.open(word)\n",
        "word_img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "ezD387MlJY4E",
        "outputId": "cf3a3c59-0b64-482f-c598-dada984a1986"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=134x49 at 0x7F06FFB00C90>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_img.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AetsqW9k2vN",
        "outputId": "07e68cb4-8e19-40ec-87b1-8ef736230488"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images, letters = recognition_another_try(\n",
        "    \"./words/57347_16\",\n",
        "    chain\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5ea0dcc3583447c88650df102eacb98a",
            "811c07172336418cb20419af9987845d",
            "52218890c444497da7812039ad1511ad",
            "d1db8261c3404eeba631350403ff8669",
            "fa36dfefd6aa4d5496bf44e6662e164f",
            "366eaed2962844da998b884671727299",
            "db788da350ff4c849fd9d028fa873960",
            "7c8b4367dbb642fcb5cd8b5d639a4317",
            "45174966cff44e4582878247593248cd",
            "82c0f4e06cb84adaaa5ea2ec930ddbe3",
            "f2fd67dd143e492f93a70e2d12b772c7"
          ]
        },
        "id": "EY4OTf6vMLpU",
        "outputId": "0ae50762-c61f-4416-e25c-b1ef8b757277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/274 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ea0dcc3583447c88650df102eacb98a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_img.crop(\n",
        "    [0, 0, 40, 49]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "nxLyL4_9mBSd",
        "outputId": "8c66feef-ee5f-4d15-b060-5152661d51a7"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=40x49 at 0x7F06FF6F6750>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_test = word_img.crop(\n",
        "    [139-50, 0, word_img.width, 49]\n",
        ")\n",
        "img_test = preprocess(\n",
        "        img_test,\n",
        "        padding=5,\n",
        "        min_contour=40,\n",
        "        deacrease_contour_if_none=True,\n",
        "      )\n",
        "\n",
        "im = img_as_bool(binarize(img_test))\n",
        "im = thin(binary_closing(skeletonize(im)))\n",
        "# plt.imshow(im, cmap='gray')\n",
        "im = im[5:-5, 5:-5]\n",
        "print(im[:, -1].sum() < 2)\n",
        "img_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "u5AL9qMqo6W0",
        "outputId": "9391dd33-b0c9-4d04-a044-822783f1655b"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=42x40 at 0x7F06E904D090>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACoAAAAoCAIAAAAHaf8HAAAFFElEQVR4nO2Ya1BTRxTHN0RyQyIkPIJiQYU2NFjAjkColQJKVew4OmIR0howBDEKMypmkKKoSFFKKa20Y0pFHoPhVcBHlPoYsVBCLVQpYCEoFkGEFgKYmIS8ZPutwiUvxjB+sOfjf8/Z3z17z57dezEQQvDqzOIVsv/Hv1r8vNkGPFeCvPwOIhkvVw/viVn1snw4G6u/JlsdcJhsE2HnwLLAhx1IvWpKlFwLV/hH2zjQy2paUEMYEzdefkF3w632X+tLnZe+xWTtIdm7CoUPQtZSf2vubhAW/nwlU1+gXAOCgridolafFe9cuJRrT5h99sX8dg9vjpt7XObJUpUWQgglSljAh9wUSFnMs3NmC9se6ouNYpcBbBDNO0au1TFqHM8v76XSognk4LIa0X9iBKsCWB3byhjFEr9JTu/QFytXQjf3uJWruHKVbgcj+IrSCc9lqbFxJZdu3J+qp5xoDwy9Frzhtl9w1ZiutCCEk7A/kpELMP4l/D/1zW8IX12pcrRNZoTXisem6VItTEhqpa85R/PPKro4pC/8cEougqezY3IMIPTue6kcNDW2SsYnQlZ/aG87vQy/7ztfeaW5rtyVKo3etFDfDA7kTWQSkv3VfkMlre+5jh7/iYBjcmKaULpMCzdsrLBfkEJZGinVn1bPA/iejyA0NMFA6lDf4g+OwM1bcjhxF2UzCInJDe7LMj4IOSWbNDTvzt2NNranpYpponJGlejGxydUAbDyNO8OSk8/OULzygRgHa8I3UCmWv1t7drN54proOw5/Ox4tZcf+w8RpC1nb2N+ZxzPyxsg28ZGMn5A6T2darpPA37+3o93ZBlgQwjzigacl3Pzr8g/2paJJYVACCUauDnyjLv3QeP4nbH1BKtd4tFpYknh9UBfjv+KLg/Pb58ahkO476AQzAtcz/lyqkjzPbL8/WyUJ7ryS4o046MaiqMNzvqFWFwKmKzavmG6q48Qb3tfJTNUy2UVg497+62s3r3K407Vu1rS7t25jnJGn3h19VUXBVXJqXutLQEAoG8E1Ar6c7Lz9yexIASD4iaRSEQkGsLz+cV1tzpclnihdP8A7rp161EiOntLRIIjjO/bG6jQgLPFjxJ25e5hb7d3xKRleEsVbZWVpTuitxMxetkKFSCRCTZkS1c3ilT5Qvf2OjQ+rKypSjSSPcZCIpeOneHdHRoaPZV7kkSZd/BYLDcpSqMBeAS6uS3+IivKQOoEBGCwSip10cBgV9jWUz2/a6TPRjFYxdseb7S0ZCA4tD/6wC3h15UUCm/e7HR2ctkY5u3ph+yODgcAjCvBxvVH4uLDo7ehVxVlqklQUNwkENx4Jp1YYkfHIdiFTqRj6cE4RJf3zLr9+wksOC1WyaaJWyIOIcgWmZ7TRac13hH39qkN+5h63VBpAd4yAMJGU5xNN5PuemoNwOP8lKoW87KBiTfdtMO/2Fl7dLUDXv6FT5no6p1bvFoF7rX1rwlkHE0RpB9N9aBRzYg3vvhM5tfNzY+dnTwpjouePO7AmPXLwMhk8glgaUGxJllLFL3nL4eal20Er1YD1ifVbXeH3d50au5IRwz2WjPjK8r+CfA9Ixuz6300cKGWQ55vfjbQ+e7PFl6uuzr6sAvvYOOLWKmxePFz7Jywwczsh5+K83i1l37s5rAiXJd49fzVyogKJM4ZHt10MQs+x7uciE8sV2phBKcG43DgXucsGu1szdSmO0f2ev9eeL3x/wK3/C9wENtOIgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for word in tqdm(words):\n",
        "#   parse_word_with_incremental_window(\n",
        "#       path=word,\n",
        "#       classifier=best_model,\n",
        "#       chain=chain,\n",
        "#       classes=class_names,\n",
        "#       markov_threshold=0.05,\n",
        "#       window_min_size=10,\n",
        "#       save_img=True,\n",
        "#       save_path=\"/content/drive/MyDrive/Disser/prediction_05-25_21-27-59\"\n",
        "#   )\n"
      ],
      "metadata": {
        "id": "uQVzdUDTbG_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_image(best_model, class_names, Image.open(\"/content/drive/MyDrive/Disser/prediction_05-25_21-27-59/п/п-3.jpg\"))"
      ],
      "metadata": {
        "id": "EwgD4Pt2l7nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfJkLKblOEHu"
      },
      "source": [
        "## Итог"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LXB--foDNFJG",
        "tXf3Zory2aTk",
        "cbHRye-ayKTU",
        "WmgsgR062Y2e",
        "Z-Oqkh902EVR",
        "OEvhUQJK2YI-",
        "7rBSegmK2Hgs",
        "c-FlTvvR2WQn",
        "zIv_O2WQ2Iqr",
        "U0o2VtFVVGpT",
        "c8agVykVMQID",
        "-Ckj2DMNKXks",
        "1Aknma84Lw2S",
        "YVS0B450OeJO",
        "UpmSTMHKd9y7",
        "hTny2XRRPbSY",
        "ZZgtZBc2PfL5",
        "yiTpmAoS_Gb0",
        "Y9iFbRkIH2ae",
        "3QrIcCntBM1M"
      ],
      "name": "Инференс",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ea0dcc3583447c88650df102eacb98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_811c07172336418cb20419af9987845d",
              "IPY_MODEL_52218890c444497da7812039ad1511ad",
              "IPY_MODEL_d1db8261c3404eeba631350403ff8669"
            ],
            "layout": "IPY_MODEL_fa36dfefd6aa4d5496bf44e6662e164f"
          }
        },
        "811c07172336418cb20419af9987845d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_366eaed2962844da998b884671727299",
            "placeholder": "​",
            "style": "IPY_MODEL_db788da350ff4c849fd9d028fa873960",
            "value": " 79%"
          }
        },
        "52218890c444497da7812039ad1511ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c8b4367dbb642fcb5cd8b5d639a4317",
            "max": 274,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45174966cff44e4582878247593248cd",
            "value": 216
          }
        },
        "d1db8261c3404eeba631350403ff8669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c0f4e06cb84adaaa5ea2ec930ddbe3",
            "placeholder": "​",
            "style": "IPY_MODEL_f2fd67dd143e492f93a70e2d12b772c7",
            "value": " 216/274 [40:16&lt;09:44, 10.07s/it]"
          }
        },
        "fa36dfefd6aa4d5496bf44e6662e164f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366eaed2962844da998b884671727299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db788da350ff4c849fd9d028fa873960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c8b4367dbb642fcb5cd8b5d639a4317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45174966cff44e4582878247593248cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82c0f4e06cb84adaaa5ea2ec930ddbe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2fd67dd143e492f93a70e2d12b772c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}