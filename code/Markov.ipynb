{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffa51f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import sent_tokenize, word_tokenize as tokenize\n",
    "from string import punctuation, whitespace\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9be333fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = \"<START>\"\n",
    "END_TOKEN = \"<END>\"\n",
    "\n",
    "punctuation += \"«»—…“”–\"\n",
    "punct = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ece99779",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"../dictation_text.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc12a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_pairs(word):\n",
    "    word: list = list(word)\n",
    "    word.append(END_TOKEN)\n",
    "    word.insert(0, START_TOKEN)\n",
    "    for i in range(len(word)-1):\n",
    "        yield (word[i], word[i+1])\n",
    "        \n",
    "def normalize(text: str):\n",
    "    tokens = [t.strip(punctuation) for t in tokenize(text)]\n",
    "    return [t for t in tokens if len(t) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a286e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = normalize(text)\n",
    "\n",
    "all_chars = list(set(''.join(corpus)) - set(whitespace))\n",
    "all_chars.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9bc7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_id = {\n",
    "    START_TOKEN: 0,\n",
    "    END_TOKEN: 1,\n",
    "}\n",
    "\n",
    "for i, char in enumerate(all_chars):\n",
    "    i += 2\n",
    "    char_to_id[char] = i\n",
    "\n",
    "id_to_char = {v: k for k, v in char_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38b9be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    rand_id = np.random.randint(0, len(id_to_char))\n",
    "    char = id_to_char[rand_id]\n",
    "    assert rand_id == char_to_id[char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31ea16c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 56)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.zeros((len(char_to_id), len(char_to_id)))\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9986bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in corpus:\n",
    "    for a,b in char_pairs(word):\n",
    "        a_id = char_to_id[a]\n",
    "        b_id = char_to_id[b]\n",
    "        M[a_id, b_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44bae872",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    a = np.random.randint(2, M.shape[0]) # ignoring START and AND tags\n",
    "    b = np.random.randint(2, M.shape[1])\n",
    "    count = sum(\n",
    "                map(lambda word: word.count(id_to_char[a] + id_to_char[b]),\n",
    "                corpus\n",
    "                   )\n",
    "            )\n",
    "    \n",
    "    assert int(M[a,b]) == count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecd5cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "for i in range(M.shape[0]):\n",
    "    _sum = np.sum(M[i])\n",
    "    if _sum > 0: M[i] /= _sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ac48166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_from_char(char: str) -> str:\n",
    "    assert len(char) == 1 or char in (START_TOKEN, END_TOKEN)\n",
    "    accum: str = char\n",
    "    prev: str = char\n",
    "    while True:\n",
    "        prev_id: int = char_to_id[prev]\n",
    "        next_id: int = np.argmax(M[prev_id])\n",
    "        next_char: str = id_to_char[next_id]\n",
    "        if next_char == END_TOKEN:\n",
    "            break\n",
    "        else:\n",
    "            accum += next_char\n",
    "            prev = next_char\n",
    "    return re.sub(\"^<START>\", '', accum)\n",
    "\n",
    "def chain_from_id(id_: int) -> int:\n",
    "    return chain_from_char(id_to_char(id_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d391da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "os.makedirs(\"markov\", exist_ok=True)\n",
    "with open(\"markov/id_to_char.json\", 'w') as f:\n",
    "    print(json.dumps(id_to_char), file=f)\n",
    "with open(\"markov/matrix.txt\", 'wb') as f:\n",
    "    np.save(f, M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
