{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737cac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import sent_tokenize, word_tokenize as tokenize\n",
    "from string import punctuation, whitespace\n",
    "import re\n",
    "\n",
    "punctuation += \"«»—…“”–\"\n",
    "punct = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c097666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovChain:\n",
    "    START_TOKEN = \"<START>\"\n",
    "    END_TOKEN = \"<END>\"\n",
    "    \n",
    "    def __init__(self, text: str, sequence_size:int):\n",
    "        \"\"\"\n",
    "        Markov chain allows us to predict the next element of a sequence based\n",
    "         on the current state. Here we predict the next character based of a\n",
    "         given sequence of characters.\n",
    "        \n",
    "        parameters:\n",
    "            text:          one string that contains the whole text on which the chain\n",
    "                            is going to be based\n",
    "            sequence_size: to predict the next element we take into account the last N\n",
    "                            elements of a given sequence. The size of this sequence is\n",
    "                            specified by this parameter.\n",
    "        \"\"\"\n",
    "        self.seq_size = sequence_size\n",
    "        self.text = text\n",
    "        self.corpus = MarkovChain.normalize(text)\n",
    "\n",
    "        self.all_chars = sorted(list(set(''.join(self.corpus)) - set(whitespace)))\n",
    "        \n",
    "        self.char_to_id = self.__char_to_id__()\n",
    "        self.id_to_char = {v: k for k, v in self.char_to_id.items()}\n",
    "\n",
    "        \n",
    "        self.M = self.__coocurrance_matrix__()\n",
    "        \n",
    "    def predict_next_char(self, chars) -> str:\n",
    "        assert len(chars) == self.seq_size\n",
    "        \n",
    "        id_tupl = tuple([self.char_to_id[char] for char in chars])\n",
    "        next_id: int = np.argmax(self.M[id_tupl])\n",
    "        if next_id == 0:\n",
    "            # Every char has equal probability, most possibly 0, and <END> tag is returned\n",
    "            return None \n",
    "        next_char: str = self.id_to_char[next_id]\n",
    "        return next_char\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(self):\n",
    "        tokens = [t.strip(punctuation) for t in tokenize(text)]\n",
    "        return [t for t in tokens if len(t) > 0]\n",
    "    \n",
    "    def __coocurrance_matrix__(self):\n",
    "        M = np.zeros(tuple(\n",
    "                    [len(self.char_to_id)] * (self.seq_size+1)\n",
    "                 ))\n",
    "        for word in self.corpus:\n",
    "            # srez has size `self.seq_size` + 1\n",
    "            for srez in self.__char_groups__(word):\n",
    "                ids = tuple([self.char_to_id[char] for char in srez])\n",
    "                M[ids] += 1\n",
    "        return M\n",
    "                \n",
    "        \n",
    "    def __char_to_id__(self):\n",
    "        char_to_id = {\n",
    "            MarkovChain.START_TOKEN: 0,\n",
    "            MarkovChain.END_TOKEN: 1,\n",
    "        }\n",
    "        for i, char in enumerate(self.all_chars):\n",
    "            i += 2\n",
    "            char_to_id[char] = i\n",
    "        return char_to_id\n",
    "        \n",
    "    def __char_groups__(self, word):\n",
    "        word: list = list(word)\n",
    "        size = self.seq_size\n",
    "\n",
    "        for i in range(size):\n",
    "            word.append(MarkovChain.END_TOKEN)\n",
    "            word.insert(0, MarkovChain.START_TOKEN)\n",
    "        \n",
    "        for i in range(len(word)-size):\n",
    "            yield tuple(word[i:i+size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22783622",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"../dictation_text.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56f4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MarkovChain(sequence_size=3,text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2543f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    rand_id = np.random.randint(0, len(chain.id_to_char))\n",
    "    char = chain.id_to_char[rand_id]\n",
    "    assert rand_id == chain.char_to_id[char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f568bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    pad = 3\n",
    "    a = np.random.randint(pad, chain.M.shape[0]-pad) # ignoring START and AND tags\n",
    "    b = np.random.randint(pad, chain.M.shape[1]-pad)\n",
    "    c = np.random.randint(pad, chain.M.shape[2]-pad)\n",
    "    d = np.random.randint(pad, chain.M.shape[3]-pad)\n",
    "    together = chain.id_to_char[a] + \\\n",
    "                chain.id_to_char[b] + \\\n",
    "                chain.id_to_char[c] + \\\n",
    "                chain.id_to_char[d]\n",
    "    count = sum(\n",
    "                map(lambda word: word.count(together),\n",
    "                chain.corpus\n",
    "                   )\n",
    "            )\n",
    "    \n",
    "    assert int(chain.M[a,b,c,d]) == count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
